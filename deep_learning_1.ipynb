{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZphdbV+4gwG9t1KH39M2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaguilar98/python_portfolio/blob/main/deep_learning_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción de Admisión de Estudiantes con Redes Neuronales usando Keras\n",
        "\n",
        "Este ejercicio está inspirado en el Nanodegree de Inteligencia Artificial de Udacity. El objetivo es predecir si aceptamos a un estudiante a graduate studies (maestría, doctorado, etc) a UCLA basándonos en 3 datos:\n",
        "* GRE Scores (Es un examen estandar en todo Estados Unidos).\n",
        "* GPA Scores (Promedio de la carrera, suele ir de 1 a 4).\n",
        "* Class Rank (El rango de la clase, es de 1 a 4).\n",
        "\n",
        "El dataset lo puedes encontrar en: http://www.ats.ucla.edu/"
      ],
      "metadata": {
        "id": "PvqVZthUONO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar Librerias Base"
      ],
      "metadata": {
        "id": "TMR6u62EONSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas               as pd\n",
        "import numpy                as np\n",
        "import matplotlib.pyplot    as plt\n",
        "import seaborn              as sns\n"
      ],
      "metadata": {
        "id": "leDxa9Mxdh8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cargar información"
      ],
      "metadata": {
        "id": "V4myZ6r3WkXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file='/content/students-data.csv'\n",
        "df=pd.read_csv(file)"
      ],
      "metadata": {
        "id": "CniFrlD8hY6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "meBgQdATd-2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df[[\"gre\",\"gpa\"]])"
      ],
      "metadata": {
        "id": "TObQuUPoXDM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_points(data):\n",
        "    \n",
        "    # Vamos a cargar los dos features numéricos de este problema: GRE y GPA. Lo cargamos como un arreglo de NumPy.\n",
        "    X = np.array(data[[\"gre\",\"gpa\"]])\n",
        "    \n",
        "    # También cargamos el valor que queremos predecir.\n",
        "    y = np.array(data[\"admit\"])\n",
        "    \n",
        "    # Separamos los features según fue aceptado o rechazado\n",
        "    admitted = X[np.argwhere(y==1)]\n",
        "    rejected = X[np.argwhere(y==0)]\n",
        "    \n",
        "    # Hacemos un scatter plot, donde el color rojo es rechazado y los celestes son aceptados.\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
        "    plt.xlabel('Test (GRE)')\n",
        "    plt.ylabel('Grades (GPA)')"
      ],
      "metadata": {
        "id": "u8NrFAmxXcjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_points(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ah-ODzW_Xhfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque no hay una relación tan clara, se puede decir que los estudiantes con mejores promedios y calificaciones en el examen son más probables de ser aceptados. De todos modos, la información no se puede separar tan fácil como en otros problemas que hemos enfrentado. Tal vez si usamos el tercer feature, el Rank, se separe mejor la información. Vamos a hacer 4 gráficas como la anterior, una para cada promedio.\n"
      ],
      "metadata": {
        "id": "7fLnLdPzONWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos el rank\n",
        "data_rank1 = df[df[\"rank\"]==1]\n",
        "data_rank2 = df[df[\"rank\"]==2]\n",
        "data_rank3 = df[df[\"rank\"]==3]\n",
        "data_rank4 = df[df[\"rank\"]==4]\n",
        "\n",
        "# Mostramos los gráficos para cada uno\n",
        "plot_points(data_rank1)\n",
        "plt.title(\"Rank 1\")\n",
        "plt.show()\n",
        "\n",
        "plot_points(data_rank2)\n",
        "plt.title(\"Rank 2\")\n",
        "plt.show()\n",
        "\n",
        "plot_points(data_rank3)\n",
        "plt.title(\"Rank 3\")\n",
        "plt.show()\n",
        "\n",
        "plot_points(data_rank4)\n",
        "plt.title(\"Rank 4\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjkrAK5AXsLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Modificamos la información para la red neuronal\n",
        "One-hot encoding\n",
        "Pandas ya tiene herramientas para hacer esto, por lo que vamos a aprovecharlas. No te preocupes mucho por el código, intenta enfocarte en lo que está ocurriendo.\n",
        "\n",
        "La función get_dummies va a separar variables categóricas en muchas variables. Por ejemplo:"
      ],
      "metadata": {
        "id": "KCPt1DPQONb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(df['rank'], prefix='rank')[:10]"
      ],
      "metadata": {
        "id": "QApkFGn3YC2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make dummy variables for rank\n",
        "one_hot_data = pd.concat([df, pd.get_dummies(df['rank'], prefix='rank')], axis=1)\n",
        "one_hot_data[:5]"
      ],
      "metadata": {
        "id": "me1V8cw1YJVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the previous rank column\n",
        "one_hot_data = one_hot_data.drop('rank', axis=1)\n",
        "\n",
        "# Print the first 10 rows of our data\n",
        "one_hot_data[:10]"
      ],
      "metadata": {
        "id": "t-ihMkuJYTd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escalando datos\n",
        "\n",
        "Todo se ve bien, pero tenemos un problema. El GRE parece ir de 200 a 800, mientras que el GPA va de 1 a 4. El rango en el GRE es mucho más grande y esto puede causar problemas. En la siguiente celda vamos a escalar la información para que los features estén entre 0 y 1."
      ],
      "metadata": {
        "id": "5NUmT6ztYeqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copiamos la información\n",
        "processed_data = one_hot_data[:]"
      ],
      "metadata": {
        "id": "Iy4OWOrXYXMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(processed_data.shape)\n",
        "# o len(dataset)\n",
        "# Escalamos ambas columnas\n",
        "processed_data['gre'] = processed_data['gre']/800\n",
        "processed_data['gpa'] = processed_data['gpa']/4.0\n",
        "processed_data[:5]"
      ],
      "metadata": {
        "id": "uczkoS_5Yrhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separar los datos en Training y Testing Set\n",
        "\n",
        "** Pregunta 2. ¿Por qué tenemos que separar en Training y Testing Set?**"
      ],
      "metadata": {
        "id": "PtqegaS1Y0l5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda separaremos en training y testing set. El testing set será el 10% de nuestra info total. No se preocupen mucho por el código, pero entiendan qué está pasando. Si corres la siguiente celda muchas veces, los resultados serán diferentes. Lo que estamos haciendo es agarrar el 90% de los datos utilizando ```np.random.choice```. Especificamos que no usamos remplazo (cuando sacamos un valor, no lo ponemos de vuelta). En la segunda línea lo que hacemos es agarrar los elementos y soltarlos (para el training y para el testing, respectivamente)."
      ],
      "metadata": {
        "id": "UduHA72vY4_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
        "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
        "\n",
        "print(\"El número de training samples es\", len(train_data))\n",
        "print(\"El número de testing samples es\", len(test_data))\n",
        "print(train_data[:7])\n",
        "print(test_data[:7])"
      ],
      "metadata": {
        "id": "MGKlnKYTYz2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separar data en features y labels\n",
        "\n",
        "**Pregunta 3. ¿Cuál es la diferencia entre features y labels?**\n",
        "\n",
        "Si te sale un error en la siguiente celda asegúrate de tener Keras instalado en tu ambiente."
      ],
      "metadata": {
        "id": "riIfGbxgZVfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "M3t0dJcBZTKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Soltamos la columna de admit en los features\n",
        "features = np.array(train_data.drop('admit', axis=1))"
      ],
      "metadata": {
        "id": "6dhFDHGuZYQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero convertimos admit en dos columnas (one-hot encoding) usando la función to_categorical de Keras. \n",
        "# Esta es la que se usa normalmente para hacer one-hot encoding.\n",
        "targets = np.array(tf.keras.utils.to_categorical(train_data['admit'], 2))"
      ],
      "metadata": {
        "id": "I-smNPhEZd3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos lo mismo para el testing set\n",
        "features_test = np.array(test_data.drop('admit', axis=1))\n",
        "targets_test = np.array(tf.keras.utils.to_categorical(test_data['admit'], 2))"
      ],
      "metadata": {
        "id": "gJ3FY9vWZixG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4. Construimos Arquitectura del Modelo"
      ],
      "metadata": {
        "id": "uxxeCne1Zpbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "n6bAqGewZm7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='sigmoid', input_shape=(6,)))\n",
        "\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# Softmax en la ultima capa, nos arroja una probabilidad de pertenencia para c/u de las clases"
      ],
      "metadata": {
        "id": "GhEXGG7HZsSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "#BinaryCrossEntropy, Optimezer Adam\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l7VjZ8viZyCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 5. Entrenamos el modelo"
      ],
      "metadata": {
        "id": "OfNk1UziZ5G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(features, targets, epochs=100, batch_size=100, verbose=0)"
      ],
      "metadata": {
        "id": "1u3Dy252Z8Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 6. Evaluamos el modelo"
      ],
      "metadata": {
        "id": "UYOgAqB-aEka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "\n",
        "score = model.evaluate(features, targets)\n",
        "print(\"\\n Training Accuracy:\", score[1])\n",
        "\n",
        "score = model.evaluate(features_test, targets_test)\n",
        "print(\"\\n Testing Accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "Yuo1zkrJaE-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1H6BD_haHMe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}